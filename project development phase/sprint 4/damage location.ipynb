{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pipe3"
      ],
      "metadata": {
        "id": "Y3nokd14Fn_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To classify location of damage - front, rear or behind."
      ],
      "metadata": {
        "id": "xUDK7vEeFqvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import h5py\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter \n",
        "from IPython.display import Image, display, clear_output\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set_style('whitegrid')"
      ],
      "metadata": {
        "id": "wA6Rg5vGFtmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, Activation, Dense, Dropout, Flatten\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.callbacks import ModelCheckpoint, History\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.regularizers import l2, l1"
      ],
      "metadata": {
        "id": "ez2gWVGAFw8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_bottleneck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "    model = VGG16(include_top=False, weights='imagenet')\n",
        "    \n",
        "    generator = datagen.flow_from_directory(train_data_dir, target_size=(img_width,img_height), batch_size=batch_size, class_mode=None, shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(generator, nb_train_samples//batch_size)\n",
        "    np.save(location+'/bottleneck_features_train.npy', bottleneck_features_train)\n",
        "    \n",
        "    generator = datagen.flow_from_directory(validation_data_dir, target_size=(img_width,img_height), batch_size=batch_size, class_mode=None, shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples//batch_size)\n",
        "    np.save(location+'/bottleneck_features_validation.npy', bottleneck_features_validation)\n"
      ],
      "metadata": {
        "id": "9H3Gjf4AFzxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_best_model_results(model_hist):\n",
        "    best_epoch = np.argmax(model_hist['val_acc'])\n",
        "    print('epoch:', best_epoch+1, ', val_acc:', model_hist['val_acc'][best_epoch], ', val_loss:', model_hist['val_loss'][best_epoch])\n"
      ],
      "metadata": {
        "id": "IMU-harGF4pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(hist, stop=50):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    axes[0].plot(range(stop), hist['acc'], label='Training')\n",
        "    axes[0].plot(range(stop), hist['val_acc'], label='Validation')\n",
        "    axes[0].set_title('Accuracy')\n",
        "    axes[0].set_ylabel('Accuracy')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].legend(loc='lower right')\n",
        "    \n",
        "    axes[1].plot(range(stop), hist['loss'], label='Training')\n",
        "    axes[1].plot(range(stop), hist['val_loss'], label='Validation')\n",
        "    axes[1].set_title('Loss')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].legend(loc='upper right')\n",
        "    \n",
        "    plt.tight_layout();\n",
        "    \n",
        "    print(\"Best Model:\")\n",
        "    print_best_model_results(hist)\n"
      ],
      "metadata": {
        "id": "M5xNf0U5F7RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_categorical_model():\n",
        "    train_data = np.load(location+'/bottleneck_features_train.npy')\n",
        "    train_labels = np.array([0]*(416) + [1]*(288) + [2]*(272))\n",
        "    train_labels = to_categorical(train_labels)\n",
        "    \n",
        "    validation_data = np.load(location+'/bottleneck_features_validation.npy')\n",
        "    validation_labels = np.array([0]*(73) + [1]*(53) + [2]*(50))\n",
        "    validation_labels = to_categorical(validation_labels)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    \n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    checkpoint = ModelCheckpoint(top_model_weights_path, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True,mode='auto')\n",
        "    \n",
        "    fit = model.fit(train_data, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(validation_data,validation_labels), callbacks=[checkpoint])\n",
        "        \n",
        "    with open(location+'/top_history.txt', 'w') as f:\n",
        "        json.dump(fit.history, f)\n",
        "    \n",
        "    return model,fit.history\n"
      ],
      "metadata": {
        "id": "YkAwL2N6F_mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune_categorical_model():\n",
        "    input_tensor = Input(shape=(256,256,3))\n",
        "    base_model = VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "    print(\"Model loaded.\")\n",
        "    top_model = Sequential()\n",
        "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "    top_model.add(Dense(256, activation='relu'))\n",
        "    top_model.add(Dropout(0.5))\n",
        "    top_model.add(Dense(3, activation='softmax'))\n",
        "    \n",
        "    top_model.load_weights(top_model_weights_path)\n",
        "    \n",
        "    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
        "    \n",
        "    for layer in model.layers[:25]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.00001, momentum=0.9), metrics=['accuracy'])\n",
        "    \n",
        "    train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "    \n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "    train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
        "    \n",
        "    validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
        "    \n",
        "    checkpoint = ModelCheckpoint(fine_tuned_model_path, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
        "    \n",
        "    fit = model.fit_generator(train_generator, steps_per_epoch=nb_train_samples//batch_size, epochs=epochs, validation_data=validation_generator, validation_steps=nb_validation_samples//batch_size, verbose=1, callbacks=[checkpoint])\n",
        "    \n",
        "    with open(location+'/ft_history.txt', 'w') as f:\n",
        "        json.dump(fit.history, f)\n",
        "        "
      ],
      "metadata": {
        "id": "pySKGD_nGDdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_categorical_model(model, directory, labels):\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "    generator = datagen.flow_from_directory(directory, target_size=(img_height,img_width), batch_size=batch_size, class_mode='categorical', shuffle=False)\n",
        "    \n",
        "    predictions = model.predict_generator(generator, len(labels))\n",
        "    \n",
        "    pred_labels = [0 if i<0.5 else 1 for i in predictions]\n",
        "    \n",
        "    print('')\n",
        "    print(classification_report(validation_labels, pred_labels))\n",
        "    print('')\n",
        "    cm = confusion_matrix(validation_labels, pred_labels)\n",
        "    return cm"
      ],
      "metadata": {
        "id": "hu6RuwzFGH6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image dataset details\n"
      ],
      "metadata": {
        "id": "OVLhRpwNGLpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "location = 'data3'\n",
        "top_model_weights_path = location+'/top_model_weights.h5'\n",
        "fine_tuned_model_path = location+'/ft_model.h5'\n",
        "model1 = location+'/bottleneck_fc_model.h5'\n",
        "train_data_dir = location+'/training'\n",
        "validation_data_dir = location+'/validation'\n",
        "train_samples = [len(os.listdir(train_data_dir+'/'+i)) for i in sorted(os.listdir(train_data_dir))]\n",
        "nb_train_samples = 976\n",
        "validation_samples = [len(os.listdir(validation_data_dir+'/'+i)) for i in sorted(os.listdir(validation_data_dir))]\n",
        "nb_validation_samples = 176\n",
        "\n",
        "img_width, img_height = 256,256\n",
        "epochs = 50\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "XKpxipL2GPOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_bottleneck_features()"
      ],
      "metadata": {
        "id": "qYNWXjyOGVty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d3_model, d3_history = train_categorical_model()\n"
      ],
      "metadata": {
        "id": "umMSkSIeGac_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(d3_history)"
      ],
      "metadata": {
        "id": "J1lHx4LIGc3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model, ft_history = finetune_categorical_model()\n"
      ],
      "metadata": {
        "id": "QxeJ_G7rGgVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model, ft_history = finetune_categorical_model()\n"
      ],
      "metadata": {
        "id": "Lo9fx4RuGjGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = evaluate_categorical_model(ft_model, validation_data_dir, validation_labels)\n"
      ],
      "metadata": {
        "id": "o2Kdm0UcGm0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t6xkX5w6GpVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipe3.1"
      ],
      "metadata": {
        "id": "NooA5kYlGs2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pipe31(image_path, model):\n",
        "    urllib.request.urlretrieve(image_path, 'save.jpg')\n",
        "    img = load_img('save.jpg', target_size=(256,256))\n",
        "    x = img_to_array(img)\n",
        "    x = x.reshape((1,)+x.shape)/255\n",
        "    pred = model.predict(x)\n",
        "    pred_labels = np.argmax(pred, axis=1)\n",
        "    d = {0:'Front', 1:'Rear', 2:'Side'}\n",
        "    for key in d.keys():\n",
        "        if pred_labels[0] == key:\n",
        "            print(\"Validating location of damage....Result:\",d[key])\n",
        "    print(\"Severity assessment complete.\")\n"
      ],
      "metadata": {
        "id": "y5Hw-4QhGtR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image('https://www.copartdirect.com/content/2007-kia-rio-front-end-damage.jpg')"
      ],
      "metadata": {
        "id": "dURub-85Gv8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe31('https://www.copartdirect.com/content/2007-kia-rio-front-end-damage.jpg', model1)\n"
      ],
      "metadata": {
        "id": "ggzEy-02GyQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image('https://drndata.com/wp-content/uploads/2016/03/car.jpg')\n"
      ],
      "metadata": {
        "id": "8f2gI-pFG10Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe31('https://drndata.com/wp-content/uploads/2016/03/car.jpg', ft_model)\n"
      ],
      "metadata": {
        "id": "yUf5PbaaG4Qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image('http://repairablecars-forsale.com/photos/Exotic_Wrecked_Cars_F430_Spider_Red_Ferrari.jpg')\n"
      ],
      "metadata": {
        "id": "5yauxBapG8Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe31('http://repairablecars-forsale.com/photos/Exotic_Wrecked_Cars_F430_Spider_Red_Ferrari.jpg', ft_model)\n"
      ],
      "metadata": {
        "id": "F4B8cNa7G-gQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}